{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustynaD00/Project-2/blob/Chatbot/First_version_of_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_DrnkwFlT-G"
      },
      "source": [
        "Installing Rasa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ffcul5QcvbFr",
        "outputId": "c4e058e9-7207-4d4e-b9d9-ec94864d4287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rasa==3.4.5\n",
            "  Downloading rasa-3.4.5-py3-none-any.whl (824 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.0/824.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting CacheControl<0.13.0,>=0.12.9 (from rasa==3.4.5)\n",
            "  Downloading CacheControl-0.12.14-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: PyJWT[crypto]<3.0.0,>=2.0.0 in /usr/lib/python3/dist-packages (from rasa==3.4.5) (2.3.0)\n",
            "Collecting SQLAlchemy<1.5.0,>=1.4.0 (from rasa==3.4.5)\n",
            "  Downloading SQLAlchemy-1.4.51-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py<1.4,>=0.9 (from rasa==3.4.5)\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aio-pika<9.0.0,>=6.7.1 (from rasa==3.4.5)\n",
            "  Downloading aio_pika-8.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiogram<2.24 (from rasa==3.4.5)\n",
            "  Downloading aiogram-2.23.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp!=3.7.4.post0,<3.9,>=3.6 (from rasa==3.4.5)\n",
            "  Downloading aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting apscheduler<3.10,>=3.6 (from rasa==3.4.5)\n",
            "  Downloading APScheduler-3.9.1.post1-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs<22.2,>=19.3 (from rasa==3.4.5)\n",
            "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0,>=1.12 (from rasa==3.4.5)\n",
            "  Downloading boto3-1.34.18-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<2.3,>=1.2 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (2.2.1)\n",
            "Collecting colorclass<2.3,>=2.2 (from rasa==3.4.5)\n",
            "  Downloading colorclass-2.2.2-py2.py3-none-any.whl (18 kB)\n",
            "Collecting coloredlogs<16,>=10 (from rasa==3.4.5)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorhash<1.3.0,>=1.0.2 (from rasa==3.4.5)\n",
            "  Downloading colorhash-1.2.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting confluent-kafka<2.0.0,>=1.9.2 (from rasa==3.4.5)\n",
            "  Downloading confluent_kafka-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dask==2022.10.2 (from rasa==3.4.5)\n",
            "  Downloading dask-2022.10.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fbmessenger<6.1.0,>=6.0.0 (from rasa==3.4.5)\n",
            "  Downloading fbmessenger-6.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: google-auth<3 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (2.17.3)\n",
            "Collecting joblib<1.3.0,>=0.15.1 (from rasa==3.4.5)\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpickle<2.3,>=1.3 (from rasa==3.4.5)\n",
            "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting jsonschema<4.17,>=3.2 (from rasa==3.4.5)\n",
            "  Downloading jsonschema-4.16.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib<3.6,>=3.1 (from rasa==3.4.5)\n",
            "  Downloading matplotlib-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mattermostwrapper<2.3,>=2.2 (from rasa==3.4.5)\n",
            "  Downloading mattermostwrapper-2.2.tar.gz (2.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting networkx<2.7,>=2.4 (from rasa==3.4.5)\n",
            "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24.0,>=1.19.2 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (1.23.5)\n",
            "Collecting packaging<21.0,>=20.0 (from rasa==3.4.5)\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (1.3.0)\n",
            "Collecting prompt-toolkit<3.0.29,>=3.0 (from rasa==3.4.5)\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.2/380.2 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2 (from rasa==3.4.5)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psycopg2-binary<2.10.0,>=2.8.2 (from rasa==3.4.5)\n",
            "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<1.10.3 (from rasa==3.4.5)\n",
            "  Downloading pydantic-1.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot<1.5,>=1.4 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (1.4.2)\n",
            "Collecting pykwalify<1.9,>=1.7 (from rasa==3.4.5)\n",
            "  Downloading pykwalify-1.8.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pymongo[srv,tls]<3.11,>=3.8 (from rasa==3.4.5)\n",
            "  Downloading pymongo-3.10.1.tar.gz (715 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m715.9/715.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (2.8.2)\n",
            "Collecting python-engineio!=5.0.0,<6,>=4 (from rasa==3.4.5)\n",
            "  Downloading python_engineio-4.8.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-socketio<6,>=4.4 (from rasa==3.4.5)\n",
            "  Downloading python_socketio-5.11.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz<2023.0,>=2019.1 (from rasa==3.4.5)\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting questionary<1.11.0,>=1.5.1 (from rasa==3.4.5)\n",
            "  Downloading questionary-1.10.0-py3-none-any.whl (31 kB)\n",
            "Collecting randomname<0.2.0,>=0.1.5 (from rasa==3.4.5)\n",
            "  Downloading randomname-0.1.5.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rasa-sdk<3.5.0,>=3.4.1 (from rasa==3.4.5)\n",
            "  Downloading rasa_sdk-3.4.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting redis<5.0,>=3.4 (from rasa==3.4.5)\n",
            "  Downloading redis-4.6.0-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex<2022.11,>=2020.6 (from rasa==3.4.5)\n",
            "  Downloading regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.23 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (2.31.0)\n",
            "Collecting rocketchat_API<1.29.0,>=0.6.31 (from rasa==3.4.5)\n",
            "  Downloading rocketchat_API-1.28.1-py3-none-any.whl (20 kB)\n",
            "Collecting ruamel.yaml<0.18.0,>=0.16.5 (from rasa==3.4.5)\n",
            "  Downloading ruamel.yaml-0.17.40-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sanic<21.13,>=21.12 (from rasa==3.4.5)\n",
            "  Downloading sanic-21.12.2-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sanic-cors<2.1.0,>=2.0.0 (from rasa==3.4.5)\n",
            "  Downloading Sanic_Cors-2.0.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting sanic-jwt<2.0.0,>=1.6.0 (from rasa==3.4.5)\n",
            "  Downloading sanic_jwt-1.8.0-py3-none-any.whl (23 kB)\n",
            "Collecting sanic-routing<0.8.0,>=0.7.2 (from rasa==3.4.5)\n",
            "  Downloading sanic_routing-0.7.2-py3-none-any.whl (23 kB)\n",
            "Collecting scikit-learn<1.2,>=0.22 (from rasa==3.4.5)\n",
            "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.9.0,>=1.4.1 (from rasa==3.4.5)\n",
            "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk<1.12.0,>=0.17.0 (from rasa==3.4.5)\n",
            "  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (67.7.2)\n",
            "Collecting sklearn-crfsuite<0.4,>=0.3 (from rasa==3.4.5)\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting slack-sdk<4.0.0,>=3.19.2 (from rasa==3.4.5)\n",
            "  Downloading slack_sdk-3.26.2-py2.py3-none-any.whl (284 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.1/284.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tarsafe<0.0.4,>=0.0.3 (from rasa==3.4.5)\n",
            "  Downloading tarsafe-0.0.3-py3-none-any.whl (5.0 kB)\n",
            "Collecting tensorflow<2.9.0,>=2.8.4 (from rasa==3.4.5)\n",
            "  Downloading tensorflow-2.8.4-cp310-cp310-manylinux2010_x86_64.whl (498.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-addons<0.18.0,>=0.17.0 (from rasa==3.4.5)\n",
            "  Downloading tensorflow_addons-0.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text<2.9.0,>=2.8.0 (from rasa==3.4.5)\n",
            "  Downloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_hub<0.13.0,>=0.12.0 (from rasa==3.4.5)\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting terminaltables<3.2.0,>=3.1.0 (from rasa==3.4.5)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.31 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (4.66.1)\n",
            "Collecting twilio<7.15,>=6.26 (from rasa==3.4.5)\n",
            "  Downloading twilio-7.14.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (4.5.0)\n",
            "Collecting typing-utils<0.2.0,>=0.1.0 (from rasa==3.4.5)\n",
            "  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n",
            "Collecting ujson<6.0,>=1.35 (from rasa==3.4.5)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webexteamssdk<1.7.0,>=1.1.1 (from rasa==3.4.5)\n",
            "  Downloading webexteamssdk-1.6.1-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa==3.4.5) (8.1.7)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa==3.4.5) (2023.6.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa==3.4.5) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa==3.4.5) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa==3.4.5) (0.12.0)\n",
            "Collecting aiormq~=6.6.3 (from aio-pika<9.0.0,>=6.7.1->rasa==3.4.5)\n",
            "  Downloading aiormq-6.6.4-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.10/dist-packages (from aio-pika<9.0.0,>=6.7.1->rasa==3.4.5) (1.9.4)\n",
            "Collecting Babel<2.10.0,>=2.9.1 (from aiogram<2.24->rasa==3.4.5)\n",
            "  Downloading Babel-2.9.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from aiogram<2.24->rasa==3.4.5) (2023.11.17)\n",
            "Collecting magic-filter>=1.0.9 (from aiogram<2.24->rasa==3.4.5)\n",
            "  Downloading magic_filter-1.0.12-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5) (1.3.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from apscheduler<3.10,>=3.6->rasa==3.4.5) (1.16.0)\n",
            "Requirement already satisfied: tzlocal!=3.*,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apscheduler<3.10,>=3.6->rasa==3.4.5) (5.2)\n",
            "Collecting botocore<1.35.0,>=1.34.18 (from boto3<2.0,>=1.12->rasa==3.4.5)\n",
            "  Downloading botocore-1.34.18-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.12->rasa==3.4.5)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.12->rasa==3.4.5)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from CacheControl<0.13.0,>=0.12.9->rasa==3.4.5) (1.0.7)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs<16,>=10->rasa==3.4.5)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa==3.4.5) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa==3.4.5) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa==3.4.5) (4.9)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<4.17,>=3.2->rasa==3.4.5)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa==3.4.5) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa==3.4.5) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa==3.4.5) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa==3.4.5) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa==3.4.5) (3.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.0.29,>=3.0->rasa==3.4.5) (0.2.12)\n",
            "Requirement already satisfied: cryptography>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3.0.0,>=2.0.0->rasa==3.4.5) (41.0.7)\n",
            "Collecting docopt>=0.6.2 (from pykwalify<1.9,>=1.7->rasa==3.4.5)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dnspython<2.0.0,>=1.16.0 (from pymongo[srv,tls]<3.11,>=3.8->rasa==3.4.5)\n",
            "  Downloading dnspython-1.16.0-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simple-websocket>=0.10.0 (from python-engineio!=5.0.0,<6,>=4->rasa==3.4.5)\n",
            "  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio<6,>=4.4->rasa==3.4.5) (0.22.1)\n",
            "Collecting fire (from randomname<0.2.0,>=0.1.5->rasa==3.4.5)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.23->rasa==3.4.5) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.23->rasa==3.4.5) (2.0.7)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml<0.18.0,>=0.16.5->rasa==3.4.5)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.0.10 (from sanic<21.13,>=21.12->rasa==3.4.5)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles>=0.6.0 (from sanic<21.13,>=21.12->rasa==3.4.5)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting websockets>=10.0 (from sanic<21.13,>=21.12->rasa==3.4.5)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5)\n",
            "  Downloading multidict-5.2.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop>=0.5.3 (from sanic<21.13,>=21.12->rasa==3.4.5)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2,>=0.22->rasa==3.4.5) (3.2.0)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite<0.4,>=0.3->rasa==3.4.5)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite<0.4,>=0.3->rasa==3.4.5) (0.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<1.5.0,>=1.4.0->rasa==3.4.5) (3.0.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (23.5.26)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (3.9.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (1.14.1)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.9,>=2.8 (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (1.60.0)\n",
            "Collecting typeguard>=2.7 (from tensorflow-addons<0.18.0,>=0.17.0->rasa==3.4.5)\n",
            "  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from webexteamssdk<1.7.0,>=1.1.1->rasa==3.4.5) (0.18.3)\n",
            "Collecting requests-toolbelt (from webexteamssdk<1.7.0,>=1.1.1->rasa==3.4.5)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pamqp==3.2.1 (from aiormq~=6.6.3->aio-pika<9.0.0,>=6.7.1->rasa==3.4.5)\n",
            "  Downloading pamqp-3.2.1-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (0.42.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3.1->PyJWT[crypto]<3.0.0,>=2.0.0->rasa==3.4.5) (1.16.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=0.3.10->dask==2022.10.2->rasa==3.4.5) (1.0.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3->rasa==3.4.5) (0.5.1)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio!=5.0.0,<6,>=4->rasa==3.4.5)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (3.5.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (3.0.1)\n",
            "Collecting typing-extensions<5.0.0,>=4.1.1 (from rasa==3.4.5)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3.1->PyJWT[crypto]<3.0.0,>=2.0.0->rasa==3.4.5) (2.21)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (2.1.3)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto->simple-websocket>=0.10.0->python-engineio!=5.0.0,<6,>=4->rasa==3.4.5)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (3.2.2)\n",
            "Building wheels for collected packages: mattermostwrapper, randomname, docopt, fire, pymongo\n",
            "  Building wheel for mattermostwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mattermostwrapper: filename=mattermostwrapper-2.2-py3-none-any.whl size=2447 sha256=39e2b2f6d9e386c5eef8fe926a6ff2442098b0290ee300fd594a85ab566be904\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/dc/02/e3239f0ea0a676085826846d32ef09b10915c0a33c817d2dbb\n",
            "  Building wheel for randomname (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for randomname: filename=randomname-0.1.5-py3-none-any.whl size=58807 sha256=94afad655981acf358469e273b6f35323847b7609953c3c5d36aff94cbf12162\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/df/c1/0bdf17c694217f49657ca36fd0239b9a243c34c27a70ff56ef\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=8dfe0997a2297810641e7ef816afb1169b01113f5ae2ff822a793a5ab990b6a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=adf9af14c2a378b9119a3b75ae9b313af767c424b68b981e43185310275279ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for pymongo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymongo: filename=pymongo-3.10.1-cp310-cp310-linux_x86_64.whl size=462804 sha256=b17692e6ed780182f59a3eec9feb6d7a52d67945f67191f3563b69789ed5487b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/ff/28/8624f4571ee5e095adb4057078b7bfc1d44d5d0a158d4f24bb\n",
            "Successfully built mattermostwrapper randomname docopt fire pymongo\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-plugin-wit, sanic-routing, pytz, python-crfsuite, keras, docopt, confluent-kafka, websockets, uvloop, ujson, typing-utils, typing-extensions, terminaltables, tensorboard-data-server, tarsafe, SQLAlchemy, slack-sdk, sklearn-crfsuite, sentry-sdk, scipy, sanic-jwt, ruamel.yaml.clib, regex, redis, pyrsistent, pymongo, psycopg2-binary, protobuf, prompt-toolkit, pamqp, packaging, networkx, multidict, magic-filter, keras-preprocessing, jsonpickle, joblib, jmespath, humanfriendly, httptools, h11, fire, dnspython, colorhash, colorclass, Babel, attrs, apscheduler, aiofiles, absl-py, wsproto, typeguard, twilio, tensorflow_hub, scikit-learn, sanic, ruamel.yaml, rocketchat_API, requests-toolbelt, randomname, questionary, pydantic, mattermostwrapper, matplotlib, jsonschema, fbmessenger, dask, coloredlogs, CacheControl, botocore, webexteamssdk, tensorflow-addons, simple-websocket, sanic-cors, s3transfer, pykwalify, google-auth-oauthlib, aiormq, aiohttp, tensorboard, rasa-sdk, python-engineio, boto3, aiogram, aio-pika, tensorflow, python-socketio, tensorflow-text, rasa\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2023.3.post1\n",
            "    Uninstalling pytz-2023.3.post1:\n",
            "      Successfully uninstalled pytz-2023.3.post1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.24\n",
            "    Uninstalling SQLAlchemy-2.0.24:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.24\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2023.6.3\n",
            "    Uninstalling regex-2023.6.3:\n",
            "      Successfully uninstalled regex-2023.6.3\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 3.0.43\n",
            "    Uninstalling prompt-toolkit-3.0.43:\n",
            "      Successfully uninstalled prompt-toolkit-3.0.43\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.2\n",
            "    Uninstalling packaging-23.2:\n",
            "      Successfully uninstalled packaging-23.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.0.4\n",
            "    Uninstalling multidict-6.0.4:\n",
            "      Successfully uninstalled multidict-6.0.4\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 3.0.2\n",
            "    Uninstalling jsonpickle-3.0.2:\n",
            "      Successfully uninstalled jsonpickle-3.0.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: Babel\n",
            "    Found existing installation: Babel 2.14.0\n",
            "    Uninstalling Babel-2.14.0:\n",
            "      Successfully uninstalled Babel-2.14.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.2.0\n",
            "    Uninstalling attrs-23.2.0:\n",
            "      Successfully uninstalled attrs-23.2.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: tensorflow_hub\n",
            "    Found existing installation: tensorflow-hub 0.15.0\n",
            "    Uninstalling tensorflow-hub-0.15.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.15.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.2\n",
            "    Uninstalling jsonschema-4.19.2:\n",
            "      Successfully uninstalled jsonschema-4.19.2\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2023.8.1\n",
            "    Uninstalling dask-2023.8.1:\n",
            "      Successfully uninstalled dask-2023.8.1\n",
            "  Attempting uninstall: CacheControl\n",
            "    Found existing installation: CacheControl 0.13.1\n",
            "    Uninstalling CacheControl-0.13.1:\n",
            "      Successfully uninstalled CacheControl-0.13.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.9.1\n",
            "    Uninstalling aiohttp-3.9.1:\n",
            "      Successfully uninstalled aiohttp-3.9.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.1\n",
            "    Uninstalling tensorboard-2.15.1:\n",
            "      Successfully uninstalled tensorboard-2.15.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "bigframes 0.18.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "distributed 2023.8.1 requires dask==2023.8.1, but you have dask 2022.10.2 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.51 which is incompatible.\n",
            "jax 0.4.23 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "jaxlib 0.4.23+cuda12.cudnn89 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "plotnine 0.12.4 requires matplotlib>=3.6.0, but you have matplotlib 3.5.3 which is incompatible.\n",
            "referencing 0.32.1 requires attrs>=22.2.0, but you have attrs 22.1.0 which is incompatible.\n",
            "statsmodels 0.14.1 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "xarray 2023.7.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Babel-2.9.1 CacheControl-0.12.14 SQLAlchemy-1.4.51 absl-py-1.3.0 aio-pika-8.3.0 aiofiles-23.2.1 aiogram-2.23.1 aiohttp-3.8.6 aiormq-6.6.4 apscheduler-3.9.1.post1 attrs-22.1.0 boto3-1.34.18 botocore-1.34.18 colorclass-2.2.2 coloredlogs-15.0.1 colorhash-1.2.1 confluent-kafka-1.9.2 dask-2022.10.2 dnspython-1.16.0 docopt-0.6.2 fbmessenger-6.0.0 fire-0.5.0 google-auth-oauthlib-0.4.6 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 jmespath-1.0.1 joblib-1.2.0 jsonpickle-2.2.0 jsonschema-4.16.0 keras-2.8.0 keras-preprocessing-1.1.2 magic-filter-1.0.12 matplotlib-3.5.3 mattermostwrapper-2.2 multidict-5.2.0 networkx-2.6.3 packaging-20.9 pamqp-3.2.1 prompt-toolkit-3.0.28 protobuf-3.19.6 psycopg2-binary-2.9.9 pydantic-1.10.2 pykwalify-1.8.0 pymongo-3.10.1 pyrsistent-0.20.0 python-crfsuite-0.9.10 python-engineio-4.8.2 python-socketio-5.11.0 pytz-2022.7.1 questionary-1.10.0 randomname-0.1.5 rasa-3.4.5 rasa-sdk-3.4.1 redis-4.6.0 regex-2022.10.31 requests-toolbelt-1.0.0 rocketchat_API-1.28.1 ruamel.yaml-0.17.40 ruamel.yaml.clib-0.2.8 s3transfer-0.10.0 sanic-21.12.2 sanic-cors-2.0.1 sanic-jwt-1.8.0 sanic-routing-0.7.2 scikit-learn-1.1.3 scipy-1.8.1 sentry-sdk-1.11.1 simple-websocket-1.0.0 sklearn-crfsuite-0.3.6 slack-sdk-3.26.2 tarsafe-0.0.3 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.4 tensorflow-addons-0.17.1 tensorflow-estimator-2.8.0 tensorflow-text-2.8.2 tensorflow_hub-0.12.0 terminaltables-3.1.10 twilio-7.14.2 typeguard-4.1.5 typing-extensions-4.9.0 typing-utils-0.1.0 ujson-5.9.0 uvloop-0.19.0 webexteamssdk-1.6.1 websockets-12.0 wsproto-1.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "matplotlib",
                  "mpl_toolkits",
                  "packaging",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Install the latest version of Rasa\n",
        "!pip install rasa==3.4.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vu4CYtxz_-oG",
        "outputId": "4e74c09f-27c2-49f2-83f4-fed5b4498cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Collecting ipython\n",
            "  Downloading ipython-8.20.0-py3-none-any.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.2/809.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.6)\n",
            "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython)\n",
            "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.1/386.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (2.16.1)\n",
            "Collecting stack-data (from ipython)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython) (1.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.12)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting pure-eval (from stack-data->ipython)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n",
            "Installing collected packages: pure-eval, prompt-toolkit, jedi, executing, asttokens, stack-data, ipython\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 3.0.28\n",
            "    Uninstalling prompt-toolkit-3.0.28:\n",
            "      Successfully uninstalled prompt-toolkit-3.0.28\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.20.0 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.51 which is incompatible.\n",
            "rasa 3.4.5 requires prompt-toolkit<3.0.29,>=3.0, but you have prompt-toolkit 3.0.43 which is incompatible.\n",
            "rasa-sdk 3.4.1 requires prompt-toolkit<3.0.29,>=3.0, but you have prompt-toolkit 3.0.43 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-2.4.1 executing-2.0.1 ipython-8.20.0 jedi-0.19.1 prompt-toolkit-3.0.43 pure-eval-0.2.2 stack-data-0.6.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -U ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFDqvlgqVEs0",
        "outputId": "90672e71-729b-4ddf-cb02-69e2d650f8d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting websockets==10.0\n",
            "  Downloading websockets-10.0.tar.gz (81 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m71.7/81.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: websockets\n",
            "  Building wheel for websockets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for websockets: filename=websockets-10.0-cp310-cp310-linux_x86_64.whl size=103015 sha256=d3686bba34cfda3ce4422b676fd19c5b7373bfdd62573d88b360d39b7b0709ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/56/64/2ecbd74736716d6bba72d533296fac530c4530a84f932bcd81\n",
            "Successfully built websockets\n",
            "Installing collected packages: websockets\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 12.0\n",
            "    Uninstalling websockets-12.0:\n",
            "      Successfully uninstalled websockets-12.0\n",
            "Successfully installed websockets-10.0\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (1.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install websockets==10.0\n",
        "!pip install websocket-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U2Szt_9xE6z",
        "outputId": "c84627b3-98c8-4923-ec63-f7d297b21886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-12 23:34:20.002760: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2024-01-12 23:34:20.002841: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2024-01-12 23:34:25.246269: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2024-01-12 23:34:25.246360: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2024-01-12 23:34:25.246401: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bc431d71e229): /proc/driver/nvidia/version does not exist\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (20.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "# Download spacy for the NLP pipeline tasks.\n",
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDKoNqcvUEFJ"
      },
      "outputs": [],
      "source": [
        "# This is  used to build information extraction or natural language understanding systems, or to pre-process text for deep learning.\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHVBIeez3cyR",
        "outputId": "216bcf06-1dc8-4455-fe7e-121cd75df921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nest_asyncio==1.3.3\n",
            "  Downloading nest_asyncio-1.3.3-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: nest_asyncio\n",
            "  Attempting uninstall: nest_asyncio\n",
            "    Found existing installation: nest-asyncio 1.5.8\n",
            "    Uninstalling nest-asyncio-1.5.8:\n",
            "      Successfully uninstalled nest-asyncio-1.5.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclassic 1.0.0 requires nest-asyncio>=1.5, but you have nest-asyncio 1.3.3 which is incompatible.\n",
            "notebook 6.5.5 requires nest-asyncio>=1.5, but you have nest-asyncio 1.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nest_asyncio-1.3.3\n"
          ]
        }
      ],
      "source": [
        "# Running asynchronous Rasa code in Jupyter Notebooks requires an extra requirement, since Jupyter Notebooks already run on event loops.\n",
        "# Install this requirement in the command line before launching jupyter:\n",
        "\n",
        "!pip install nest_asyncio==1.3.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFVs_ym8EUTy",
        "outputId": "e793975e-c928-4418-e649-0af157fbf104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event loop ready.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import rasa\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "print(\"Event loop ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZsqX3irEv7O"
      },
      "outputs": [],
      "source": [
        "# Prepare for creating a project space for the Cruise Chatbot\n",
        "from rasa.cli.scaffold import create_initial_project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnIOywUKE6F5"
      },
      "outputs": [],
      "source": [
        "# Assign a name to the project\n",
        "project = \"cruise-chatbot\"\n",
        "create_initial_project(project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjxVHRJCE-u5",
        "outputId": "5a00ef07-ca94-43ef-df60-533787b9d5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['data', 'endpoints.yml', 'credentials.yml', 'actions', 'config.yml', 'domain.yml', 'tests']\n"
          ]
        }
      ],
      "source": [
        "# move into project directory and show files\n",
        "os.chdir(project)\n",
        "print(os.listdir(\".\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N_1uA1KPkBt",
        "outputId": "d6b81ab1-1095-466b-dbee-e608b4abe838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config.yml data/ domain.yml models/\n"
          ]
        }
      ],
      "source": [
        "# To train the model,by passing in the paths to the rasa.train function.\n",
        "# Note that the training files are passed as a list.\n",
        "# When training has finished, rasa.train returns the path where the trained model has been saved.\n",
        "\n",
        "config = \"config.yml\"\n",
        "training_files = \"data/\"\n",
        "domain = \"domain.yml\"\n",
        "output = \"models/\"\n",
        "print(config, training_files, domain, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrdOIlziPxEo",
        "outputId": "cd3876c6-aca1-4683-dc88-14a7b46ee91e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasa/engine/caching.py:152: MovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base: DeclarativeMeta = declarative_base()\n",
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b(0lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk\u001b(B\n",
            "\u001b(0x\u001b(B Rasa Open Source reports anonymous usage telemetry to help improve the product \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B for all its users.                                                             \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B                                                                                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B If you'd like to opt-out, you can use `rasa telemetry disable`.                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B To learn more, check out https://rasa.com/docs/rasa/telemetry/telemetry.       \u001b(0x\u001b(B\n",
            "\u001b(0mqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj\u001b(B\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94mThe configuration for policies and pipeline was chosen automatically. It was written into the config file at 'config.yml'.\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasa/utils/tensorflow/model_data.py:774: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.concatenate(np.array(f)),\n",
            "Epochs: 100%|██████████| 100/100 [00:43<00:00,  2.31it/s, t_loss=1.12, i_acc=1]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 300.10it/s, # trackers=1]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 304.14it/s, # trackers=3]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 109.90it/s, # trackers=12]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 31.46it/s, # trackers=39]\n",
            "Processed rules: 100%|██████████| 2/2 [00:00<00:00, 357.13it/s, # trackers=1]\n",
            "Processed trackers: 100%|██████████| 3/3 [00:00<00:00, 102.61it/s, # action=12]\n",
            "Processed actions: 12it [00:00, 398.14it/s, # examples=12]\n",
            "Processed trackers: 100%|██████████| 2/2 [00:00<00:00, 172.20it/s, # action=5]\n",
            "Processed actions: 5it [00:00, 1123.51it/s, # examples=4]\n",
            "Processed trackers: 100%|██████████| 3/3 [00:00<00:00, 217.89it/s, # action=12]\n",
            "Processed trackers: 100%|██████████| 2/2 [00:00<00:00, 1228.20it/s]\n",
            "Processed trackers: 100%|██████████| 5/5 [00:00<00:00, 400.37it/s]\n",
            "Processed trackers: 100%|██████████| 120/120 [00:00<00:00, 845.43it/s, # action=30]\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/utils/tensorflow/model_data_utils.py:388: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.array(values), number_of_dimensions=4\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/utils/tensorflow/model_data_utils.py:404: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  MASK: [FeatureArray(np.array(attribute_masks), number_of_dimensions=3)]\n",
            "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "Epochs: 100%|██████████| 100/100 [00:24<00:00,  4.07it/s, t_loss=1.18, loss=1.02, acc=1]\n",
            "WARNING:rasa.shared.utils.common:The UnexpecTED Intent Policy is currently experimental and might change or be removed in the future 🔬 Please share your feedback on it in the forum (https://forum.rasa.com) to help us make this feature ready for production.\n",
            "Processed trackers: 100%|██████████| 120/120 [00:00<00:00, 1317.23it/s, # intent=12]\n",
            "Epochs: 100%|██████████| 100/100 [00:20<00:00,  4.86it/s, t_loss=0.131, loss=0.0176, acc=1]\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/core/policies/unexpected_intent_policy.py:839: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
            "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
            "  quantile_values = np.quantile(  # type: ignore[call-overload]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mYour Rasa model is trained and saved at 'models/20240112-233917-soft-dominant.tar.gz'.\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TrainingResult(model='models/20240112-233917-soft-dominant.tar.gz', code=0, dry_run_results=None)\n"
          ]
        }
      ],
      "source": [
        "# Train a ML model\n",
        "model_path = rasa.train(domain, config, [training_files], output)\n",
        "print(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--XV_jksm6mN"
      },
      "outputs": [],
      "source": [
        "# Chat with your assistant#\n",
        "\n",
        "from rasa.jupyter import chat\n",
        "\n",
        "#endpoints = 'endpoints.yml'\n",
        "\n",
        "endpoints = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUCSgxbCo1Cq",
        "outputId": "9dad45c6-b744-4626-881b-33a701b5c424"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "WARNING:rasa.shared.utils.common:The UnexpecTED Intent Policy is currently experimental and might change or be removed in the future 🔬 Please share your feedback on it in the forum (https://forum.rasa.com) to help us make this feature ready for production.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your bot is ready to talk! Type your messages here or send '/stop'.\n"
          ]
        }
      ],
      "source": [
        "# Start the conversation\n",
        "chat(model_path.model, endpoints)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_7p6gkaorul"
      },
      "source": [
        "## **Cruise CHATBOT - TRAINING DATA **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHP9YBkSKpII"
      },
      "outputs": [],
      "source": [
        "from rasa_sdk import Action, Tracker\n",
        "from rasa_sdk.events import SlotSet\n",
        "from rasa_sdk.executor import CollectingDispatcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbhgLbmZ78on",
        "outputId": "d04da76e-a4d7-4d08-8940-ab4792cf720a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting data/stories.md\n"
          ]
        }
      ],
      "source": [
        "%%writefile data/stories.md\n",
        "\n",
        "version: \"3.1\"\n",
        "\n",
        "stories:\n",
        "\n",
        "- story: happy path\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "\n",
        "- story: booking a booking cruise\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: Booking_cruise\n",
        "  - action: utter_Conf_destination\n",
        "  - intent: Conf_destination\n",
        "  - action: utter_Conf_duration\n",
        "  - intent: Conf_duration\n",
        "  - action: utter_room_book\n",
        "  - intent: room_book\n",
        "  - action: utter_bed_conf\n",
        "  - intent: bed_conf\n",
        "  - action: utter_confirm\n",
        "  - intent: affirm\n",
        "  - action: utter_pers_info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRdpw5prqaw1",
        "outputId": "dceaf357-03b4-4623-b378-f2384a799fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting data/nlu.md\n"
          ]
        }
      ],
      "source": [
        "%%writefile data/nlu.md\n",
        "\n",
        "version: \"3.1\"\n",
        "\n",
        "nlu:\n",
        "- intent: greet\n",
        "  examples: |\n",
        "    - hey\n",
        "    - hello\n",
        "    - hi\n",
        "    - hello there\n",
        "    - good morning\n",
        "    - good evening\n",
        "    - moin\n",
        "    - hey there\n",
        "    - let's go\n",
        "    - hey dude\n",
        "    - goodmorning\n",
        "    - goodevening\n",
        "    - good afternoon\n",
        "\n",
        "- intent: goodbye\n",
        "  examples: |\n",
        "    - cu\n",
        "    - good by\n",
        "    - cee you later\n",
        "    - good night\n",
        "    - bye\n",
        "    - goodbye\n",
        "    - have a nice day\n",
        "    - see you around\n",
        "    - bye bye\n",
        "    - see you later\n",
        "\n",
        "- intent: affirm\n",
        "  examples: |\n",
        "    - yes\n",
        "    - y\n",
        "    - indeed\n",
        "    - of course\n",
        "    - that sounds good\n",
        "    - correct\n",
        "\n",
        "- intent: deny\n",
        "  examples: |\n",
        "    - no\n",
        "    - n\n",
        "    - never\n",
        "    - I don't think so\n",
        "    - don't like that\n",
        "    - no way\n",
        "    - not really\n",
        "\n",
        "- intent: bot_challenge\n",
        "  examples: |\n",
        "    - are you a bot?\n",
        "    - are you a human?\n",
        "    - am I talking to a bot?\n",
        "    - am I talking to a human?\n",
        "\n",
        "- intent: Booking_cruise\n",
        "  examples: |\n",
        "   - I would like to book a cruise\n",
        "   - I want to go on a cruise\n",
        "   - Book a cruise\n",
        "   - Can I book a cruise?\n",
        "\n",
        "- intent: Conf_destination\n",
        "  examples: |\n",
        "   - I want to go to spain\n",
        "   - Spain\n",
        "   - I want cruise to Spain\n",
        "\n",
        "- intent: Conf_duration\n",
        "  examples: |\n",
        "   - I want to go for a month\n",
        "   - I want to travel for a month\n",
        "   - one month\n",
        "\n",
        "- intent: room_book\n",
        "  examples: |\n",
        "   - I want a suite\n",
        "   - I would like to stay in a suite\n",
        "   - Suite room please\n",
        "\n",
        "- intent: bed_conf\n",
        "  examples: |\n",
        "   - I need 6 beds\n",
        "   - I would like 6 beds\n",
        "   - 6 beds\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc7IqsEuSO1y",
        "outputId": "3df6e70c-2a48-42bb-ec0d-ea7241a2912d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing domain.md\n"
          ]
        }
      ],
      "source": [
        "%%writefile domain.md\n",
        "\n",
        "version: \"3.1\"\n",
        "\n",
        "intents:\n",
        "  - greet\n",
        "  - goodbye\n",
        "  - affirm\n",
        "  - deny\n",
        "  - bot_challenge\n",
        "  - Booking_cruise\n",
        "  - Conf_destination\n",
        "  - Conf_duration\n",
        "  - room_book\n",
        "  - bed_conf\n",
        "\n",
        "\n",
        "responses:\n",
        "  utter_greet:\n",
        "  - text: \"Hey! How may i help you?\"\n",
        "\n",
        "  utter_did_that_help:\n",
        "  - text: \"Did that help you?\"\n",
        "\n",
        "  utter_happy:\n",
        "  - text: \" Glad youre okay \"\n",
        "\n",
        "  utter_goodbye:\n",
        "  - text: \"Bye\"\n",
        "\n",
        "  utter_iamabot:\n",
        "  - text: \"I am a bot, powered by Rasa.\"\n",
        "\n",
        "  utter_Conf_destination:\n",
        "  - text: \"Amazing, lets get you started, firstly, where would you like to go?\"\n",
        "\n",
        "  utter_Conf_duration:\n",
        "  - text: \"Amazing, and how long do you want to travel for?\"\n",
        "\n",
        "  utter_room_book:\n",
        "  - text: \"Great! And what sort of room would you like?\"\n",
        "\n",
        "  utter_bed_conf:\n",
        "  - text: \"And how many beds do you need?\"\n",
        "\n",
        "  utter_confirm:\n",
        "  - text: \"That is everything, would you like to make the booking?\"\n",
        "\n",
        "  utter_pers_info:\n",
        "  - text: \"Brilliant, please confirm your full name and your date of birth\"\n",
        "\n",
        "session_config:\n",
        "  session_expiration_time: 60\n",
        "  carry_over_slots_to_new_session: true\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yp5XVt3Gam9g",
        "outputId": "91dc2a83-d7d0-4664-bdd4-524b878e2408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94mThe configuration for policies and pipeline was chosen automatically. It was written into the config file at 'config.yml'.\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 100%|██████████| 100/100 [00:49<00:00,  2.00it/s, t_loss=2.07, i_acc=1]\n",
            "Processed story blocks: 100%|██████████| 391/391 [00:00<00:00, 440.07it/s, # trackers=1]\n",
            "Processed story blocks: 100%|██████████| 391/391 [00:12<00:00, 31.79it/s, # trackers=50]\n",
            "Processed story blocks: 100%|██████████| 391/391 [00:17<00:00, 22.64it/s, # trackers=50]\n",
            "Processed story blocks: 100%|██████████| 391/391 [00:18<00:00, 21.49it/s, # trackers=50]\n",
            "Processed rules: 100%|██████████| 2/2 [00:00<00:00, 428.54it/s, # trackers=1]\n",
            "Processed trackers: 100%|██████████| 349/349 [00:02<00:00, 135.27it/s, # action=1715]\n",
            "Processed actions: 1715it [00:02, 744.33it/s, # examples=1715]\n",
            "Processed trackers: 100%|██████████| 2/2 [00:00<00:00, 232.24it/s, # action=5]\n",
            "Processed actions: 5it [00:00, 1404.56it/s, # examples=4]\n",
            "Processed trackers: 100%|██████████| 349/349 [00:01<00:00, 182.86it/s, # action=1715]\n",
            "Processed trackers: 100%|██████████| 2/2 [00:00<00:00, 548.13it/s]\n",
            "Processed trackers: 100%|██████████| 351/351 [00:02<00:00, 119.91it/s]\n",
            "Processed trackers: 100%|██████████| 849/849 [00:01<00:00, 604.28it/s, # action=427]\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/utils/tensorflow/model_data_utils.py:388: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.array(values), number_of_dimensions=4\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/utils/tensorflow/model_data_utils.py:404: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  MASK: [FeatureArray(np.array(attribute_masks), number_of_dimensions=3)]\n",
            "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "Epochs: 100%|██████████| 100/100 [00:38<00:00,  2.63it/s, t_loss=0.353, loss=0.163, acc=1]\n",
            "WARNING:rasa.shared.utils.common:The UnexpecTED Intent Policy is currently experimental and might change or be removed in the future 🔬 Please share your feedback on it in the forum (https://forum.rasa.com) to help us make this feature ready for production.\n",
            "Processed trackers: 100%|██████████| 849/849 [00:01<00:00, 526.21it/s, # intent=214]\n"
          ]
        },
        {
          "ename": "GraphComponentException",
          "evalue": "Error running graph component for node train_UnexpecTEDIntentPolicy2.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/engine/graph.py:464\u001b[0m, in \u001b[0;36mGraphNode.__call__\u001b[0;34m(self, *inputs_from_previous_nodes)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_component\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrun_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidConfigException:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Pass through somewhat expected exception to allow more fine granular\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# handling of exceptions.\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/core/policies/ted_policy.py:719\u001b[0m, in \u001b[0;36mTEDPolicy.train\u001b[0;34m(self, training_trackers, domain, precomputations, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m training_trackers \u001b[38;5;241m=\u001b[39m SupportedData\u001b[38;5;241m.\u001b[39mtrackers_for_supported_data(\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupported_data(), training_trackers\n\u001b[1;32m    717\u001b[0m )\n\u001b[0;32m--> 719\u001b[0m model_data, label_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_for_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_trackers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecomputations\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_data\u001b[38;5;241m.\u001b[39mis_empty():\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/core/policies/ted_policy.py:609\u001b[0m, in \u001b[0;36mTEDPolicy._prepare_for_training\u001b[0;34m(self, trackers, domain, precomputations, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m# dealing with training data\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m tracker_state_features, label_ids, entity_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_featurize_for_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_trackers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecomputations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecomputations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbilou_tagging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mBILOU_FLAG\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracker_state_features:\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/core/policies/policy.py:241\u001b[0m, in \u001b[0;36mPolicy._featurize_for_training\u001b[0;34m(self, training_trackers, domain, precomputations, bilou_tagging, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform training trackers into a vector representation.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03mThe trackers, consisting of multiple turns, will be transformed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m      for all dialogue turns in all training trackers\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m state_features, label_ids, entity_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeaturizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeaturize_trackers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_trackers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecomputations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecomputations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbilou_tagging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbilou_tagging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_action_unlikely_intent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSupportedData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mML_DATA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m max_training_samples \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_training_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/core/featurizers/tracker_featurizers.py:351\u001b[0m, in \u001b[0;36mTrackerFeaturizer.featurize_trackers\u001b[0;34m(self, trackers, domain, precomputations, bilou_tagging, ignore_action_unlikely_intent)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tracker_state_features, np\u001b[38;5;241m.\u001b[39mndarray(trackers_as_labels), []\n\u001b[0;32m--> 351\u001b[0m label_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_labels_to_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrackers_as_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m entity_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_entity_tags(\n\u001b[1;32m    354\u001b[0m     trackers_as_entities, precomputations, bilou_tagging\n\u001b[1;32m    355\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/core/featurizers/tracker_featurizers.py:921\u001b[0m, in \u001b[0;36mIntentMaxHistoryTrackerFeaturizer._convert_labels_to_ids\u001b[0;34m(cls, trackers_as_intents, domain)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;66;03m# store labels in numpy arrays so that it corresponds to np arrays\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;66;03m# of input features\u001b[39;00m\n\u001b[0;32m--> 921\u001b[0m label_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    922\u001b[0m     [domain\u001b[38;5;241m.\u001b[39mintents\u001b[38;5;241m.\u001b[39mindex(intent) \u001b[38;5;28;01mfor\u001b[39;00m intent \u001b[38;5;129;01min\u001b[39;00m tracker_intents]\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tracker_intents \u001b[38;5;129;01min\u001b[39;00m trackers_as_intents\n\u001b[1;32m    924\u001b[0m ]\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_pad_label_ids(label_ids))\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/core/featurizers/tracker_featurizers.py:922\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;66;03m# store labels in numpy arrays so that it corresponds to np arrays\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;66;03m# of input features\u001b[39;00m\n\u001b[1;32m    921\u001b[0m label_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 922\u001b[0m     [domain\u001b[38;5;241m.\u001b[39mintents\u001b[38;5;241m.\u001b[39mindex(intent) \u001b[38;5;28;01mfor\u001b[39;00m intent \u001b[38;5;129;01min\u001b[39;00m tracker_intents]\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tracker_intents \u001b[38;5;129;01min\u001b[39;00m trackers_as_intents\n\u001b[1;32m    924\u001b[0m ]\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_pad_label_ids(label_ids))\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/core/featurizers/tracker_featurizers.py:922\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;66;03m# store labels in numpy arrays so that it corresponds to np arrays\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;66;03m# of input features\u001b[39;00m\n\u001b[1;32m    921\u001b[0m label_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 922\u001b[0m     [\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintent\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m intent \u001b[38;5;129;01min\u001b[39;00m tracker_intents]\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tracker_intents \u001b[38;5;129;01min\u001b[39;00m trackers_as_intents\n\u001b[1;32m    924\u001b[0m ]\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_pad_label_ids(label_ids))\n",
            "\u001b[0;31mValueError\u001b[0m: 'Conf_destination_2weeks' is not in list",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mGraphComponentException\u001b[0m                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train a ML model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[43mrasa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtraining_files\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_path)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/api.py:105\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(domain, config, training_files, output, dry_run, force_training, fixed_model_name, persist_nlu_training_data, core_additional_arguments, nlu_additional_arguments, model_to_finetune, finetuning_epoch_fraction)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs Rasa Core and NLU training in `async` loop.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    An instance of `TrainingResult`.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrasa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_training\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_nlu_training_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_nlu_training_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcore_additional_arguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcore_additional_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnlu_additional_arguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnlu_additional_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_to_finetune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_to_finetune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinetuning_epoch_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetuning_epoch_fraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/model_training.py:207\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(domain, config, training_files, output, dry_run, force_training, fixed_model_name, persist_nlu_training_data, core_additional_arguments, nlu_additional_arguments, model_to_finetune, finetuning_epoch_fraction)\u001b[0m\n\u001b[1;32m    204\u001b[0m _check_unresolved_slots(domain_object, stories)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m telemetry\u001b[38;5;241m.\u001b[39mtrack_model_training(file_importer, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrasa\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_train_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_importer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_finetune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_to_finetune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_full_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_nlu_training_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_nlu_training_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinetuning_epoch_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetuning_epoch_fraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcore_additional_arguments\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnlu_additional_arguments\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/model_training.py:286\u001b[0m, in \u001b[0;36m_train_graph\u001b[0;34m(file_importer, training_type, output_path, fixed_model_name, model_to_finetune, force_full_training, dry_run, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m full_model_path \u001b[38;5;241m=\u001b[39m Path(output_path, model_name)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m telemetry\u001b[38;5;241m.\u001b[39mtrack_model_training(\n\u001b[1;32m    284\u001b[0m     file_importer, model_type\u001b[38;5;241m=\u001b[39mtraining_type\u001b[38;5;241m.\u001b[39mmodel_type\n\u001b[1;32m    285\u001b[0m ):\n\u001b[0;32m--> 286\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_importer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_retraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_full_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_finetuning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_finetuning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     rasa\u001b[38;5;241m.\u001b[39mshared\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcli\u001b[38;5;241m.\u001b[39mprint_success(\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour Rasa model is trained and saved at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m     )\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TrainingResult(\u001b[38;5;28mstr\u001b[39m(full_model_path), \u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/engine/training/graph_trainer.py:105\u001b[0m, in \u001b[0;36mGraphTrainer.train\u001b[0;34m(self, model_configuration, importer, output_filename, force_retraining, is_finetuning)\u001b[0m\n\u001b[1;32m     93\u001b[0m graph_runner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_runner_class\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     94\u001b[0m     graph_schema\u001b[38;5;241m=\u001b[39mpruned_training_schema,\n\u001b[1;32m     95\u001b[0m     model_storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_storage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    103\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning the pruned train graph with real node execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m \u001b[43mgraph_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mPLACEHOLDER_IMPORTER\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimporter\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_storage\u001b[38;5;241m.\u001b[39mcreate_model_package(\n\u001b[1;32m    108\u001b[0m     output_filename, model_configuration, domain\n\u001b[1;32m    109\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/engine/runner/dask.py:101\u001b[0m, in \u001b[0;36mDaskGraphRunner.run\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     95\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning graph with inputs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, targets: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtargets\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execution_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     dask_result \u001b[38;5;241m=\u001b[39m \u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_targets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(dask_result)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py:557\u001b[0m, in \u001b[0;36mget_sync\u001b[0;34m(dsk, keys, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A naive synchronous version of get_async\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03mCan be useful for debugging.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# if num_workers present, remove it\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronous_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronous_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py:500\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaiting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mready\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    499\u001b[0m     fire_tasks(chunksize)\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, res_info, failed \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqueue_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m    502\u001b[0m             exc, tb \u001b[38;5;241m=\u001b[39m loads(res_info)\n",
            "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py:542\u001b[0m, in \u001b[0;36mSynchronousExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m fut \u001b[38;5;241m=\u001b[39m Future()\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     fut\u001b[38;5;241m.\u001b[39mset_result(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     fut\u001b[38;5;241m.\u001b[39mset_exception(e)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py:238\u001b[0m, in \u001b[0;36mbatch_execute_tasks\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_execute_tasks\u001b[39m(it):\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    Batch computing of multiple tasks with `execute_task`\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [execute_task(\u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m it]\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py:238\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_execute_tasks\u001b[39m(it):\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    Batch computing of multiple tasks with `execute_task`\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m it]\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py:229\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    227\u001b[0m     failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 229\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpack_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key, result, failed\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rasa/engine/graph.py:471\u001b[0m, in \u001b[0;36mGraphNode.__call__\u001b[0;34m(self, *inputs_from_previous_nodes)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RasaException):\n\u001b[0;32m--> 471\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GraphComponentException(\n\u001b[1;32m    472\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError running graph component for node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    475\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    476\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError running graph component for node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         )\n",
            "\u001b[0;31mGraphComponentException\u001b[0m: Error running graph component for node train_UnexpecTEDIntentPolicy2."
          ]
        }
      ],
      "source": [
        "# Train a ML model\n",
        "model_path = rasa.train(domain, config, [training_files], output)\n",
        "print(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2CiToecSt6V",
        "outputId": "c9fd5b2f-146e-4314-d6eb-6d5b038db570"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from rasa.jupyter import chat\n",
        "#endpoints = 'endpoints.yml'\n",
        "endpoints = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1nCBzU_X-hM",
        "outputId": "7e4a48f0-3cfb-46f3-c99f-b1844ed1baac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "WARNING:rasa.shared.utils.common:The UnexpecTED Intent Policy is currently experimental and might change or be removed in the future 🔬 Please share your feedback on it in the forum (https://forum.rasa.com) to help us make this feature ready for production.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your bot is ready to talk! Type your messages here or send '/stop'.\n",
            "hello\n",
            "\u001b[92mHello! Welcome to Royal Caribbean! My name is SunShine, how may I assist you today?\u001b[0m\n",
            "I would like to go on a cruise\n",
            "\u001b[92mAmazing, lets get you started, firstly, where would you like to go? \n",
            " \n",
            " Here are some of our popular destinations: \n",
            " \n",
            " Europe: \u001b[0m\n",
            "\u001b[92m 1) France \u001b[0m\n",
            "\u001b[92m 2) Norway \u001b[0m\n",
            "\u001b[92m 3) Coatia \u001b[0m\n",
            "\u001b[92m 4) Greece \n",
            " \n",
            " Asia: \u001b[0m\n",
            "\u001b[92m 1) Thailand \u001b[0m\n",
            "\u001b[92m 2) China \u001b[0m\n",
            "\u001b[92m 3) Japan \n",
            " \n",
            " North America: \u001b[0m\n",
            "\u001b[92m 1) Florida \u001b[0m\n",
            "\u001b[92m 2) Hawaii \u001b[0m\n",
            "\u001b[92m 3) Canada \n",
            " \n",
            " Or go to the following link to see the full list of our destinations: https://www.royalcaribbean.com/gbr/en/cruise-destinations?\u001b[0m\n",
            "/stop\n"
          ]
        }
      ],
      "source": [
        "# Chat with your assistant#\n",
        "# To start chatting to an assistant, call the chat function, passing in the path to your saved model.\n",
        "# If you do not have custom actions you can set endpoints = None or omit it:\n",
        "chat(model_path.model, endpoints)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3HlrxQ3qc6h"
      },
      "source": [
        "# **Chat with the Hotel Chatbot - several times to test it.**\n",
        "Make adjustments to the rules.yml and stories.yml and RE-TEST  to make the dialogue more effective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbxxBbmeZmTt"
      },
      "outputs": [],
      "source": [
        "# Evaluate your model against test data#\n",
        "# Rasa has a convenience function for getting your training data.\n",
        "# Rasa's get_core_directory and get_nlu_directory are functions which recursively find all the stories or NLU data files and\n",
        "# copies them into temporary directories.\n",
        "# The return values are the paths to these newly created directories.\n",
        "\n",
        "import rasa.shared.data as data\n",
        "nlu_data_directory = data.get_nlu_directory(training_files)\n",
        "stories_directory = data.get_core_directory(training_files)\n",
        "print(stories_directory, nlu_data_directory)\n",
        "rasa.test(model_path, stories_directory, nlu_data_directory)\n",
        "print(\"Done testing.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BroytnpprIMy"
      },
      "source": [
        "# Review the test.stories. Check if it is they reflect your Chatbot stories"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}